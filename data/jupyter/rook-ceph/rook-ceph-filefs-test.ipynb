{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78736536",
   "metadata": {},
   "source": [
    "### CephFS \n",
    "\n",
    "Wir verwenden [Host Storage Cluster](https://rook.io/docs/rook/v1.11/CRDs/Cluster/host-cluster/)\n",
    "\n",
    "Überprüfen, ob die CephFS-CSI-Plugins korrekt laufen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897d0565",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "kubectl -n rook-ceph get pods -l app=csi-cephfsplugin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07ae5cb",
   "metadata": {},
   "source": [
    "Zuerst brauchen wie ein Filesystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51a155f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "kubectl apply -f https://raw.githubusercontent.com/rook/rook/1cf0a83ead305f0dab510827269bbde495765bc3/deploy/examples/filesystem-test.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f673200",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964fbadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "kubectl apply -f - <<EOF\n",
    "apiVersion: ceph.rook.io/v1\n",
    "kind: CephFilesystem\n",
    "metadata:\n",
    "  name: myfs\n",
    "\n",
    "spec:\n",
    "  metadataPool:\n",
    "    replicated:\n",
    "      size: 3\n",
    "  dataPools:\n",
    "    - replicated:\n",
    "        size: 3\n",
    "  preserveFilesystemOnDelete: true\n",
    "  metadataServer:\n",
    "    activeCount: 1\n",
    "    activeStandby: true\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002036e3",
   "metadata": {},
   "source": [
    "Prüfen, ob CephFS korrekt eingerichtet ist\n",
    "Überprüfe, ob CephFS bereits läuft:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378257d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "kubectl -n rook-ceph get CephCluster,cephfilesystems,CephFilesystemSubVolumeGroup\n",
    "kubectl -n rook-ceph describe CephCluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9656cae2",
   "metadata": {},
   "source": [
    "*Evtl. könnten die Zugriffsberechtigungen RBAC nicht vorhanden sein, deshalb setzen wir diese*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf126153",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "kubectl apply -f - <<EOF\n",
    "apiVersion: rbac.authorization.k8s.io/v1\n",
    "kind: ClusterRole\n",
    "metadata:\n",
    "  name: ceph-csi-provisioner\n",
    "rules:\n",
    "  - apiGroups: [\"\"]\n",
    "    resources: [\"persistentvolumes\"]\n",
    "    verbs: [\"get\", \"list\", \"watch\", \"create\", \"delete\", \"patch\", \"update\"]\n",
    "  - apiGroups: [\"storage.k8s.io\"]\n",
    "    resources: [\"storageclasses\"]\n",
    "    verbs: [\"get\", \"list\", \"watch\"]\n",
    "  - apiGroups: [\"storage.k8s.io\"]\n",
    "    resources: [\"volumeattachments\"]\n",
    "    verbs: [\"get\", \"list\", \"watch\", \"patch\", \"update\"]\n",
    "---\n",
    "apiVersion: rbac.authorization.k8s.io/v1\n",
    "kind: ClusterRoleBinding\n",
    "metadata:\n",
    "  name: ceph-csi-provisioner-binding\n",
    "roleRef:\n",
    "  apiGroup: rbac.authorization.k8s.io\n",
    "  kind: ClusterRole\n",
    "  name: ceph-csi-provisioner\n",
    "subjects:\n",
    "  - kind: ServiceAccount\n",
    "    name: rook-csi-cephfs-provisioner\n",
    "    namespace: rook-ceph\n",
    "EOF\n",
    "# braucht Restart\n",
    "kubectl -n rook-ceph delete pod -l app=csi-cephfsplugin-provisioner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cf613b",
   "metadata": {},
   "source": [
    "### StorageClass für Rook-Ceph erstellen.\n",
    "\n",
    "Mit dieser werden keine PV erstellt.\n",
    "\n",
    "Alternative microk8s-hostpath vom Addon hostpath-storage verwenden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41cb0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "kubectl apply -f - <<EOF\n",
    "apiVersion: storage.k8s.io/v1\n",
    "kind: StorageClass\n",
    "metadata:\n",
    "  name: rook-cephfs \n",
    "provisioner: rook-ceph.cephfs.csi.ceph.com\n",
    "parameters:\n",
    "  clusterID: rook-ceph\n",
    "  fsName: myfs\n",
    "  pool: myfs-data0\n",
    "  csi.storage.k8s.io/provisioner-secret-name: rook-csi-cephfs-provisioner\n",
    "  csi.storage.k8s.io/provisioner-secret-namespace: rook-ceph\n",
    "  csi.storage.k8s.io/node-stage-secret-name: rook-csi-cephfs-node\n",
    "  csi.storage.k8s.io/node-stage-secret-namespace: rook-ceph\n",
    "  csi.storage.k8s.io/fstype: ext4\n",
    "reclaimPolicy: Delete\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68b5c6d",
   "metadata": {},
   "source": [
    "### PersistentVolume und Persistent Volume Claim (PVC) für Ceph RBD erstellen\n",
    "\n",
    "**Hinweis** PersistentVolume sollte eigentlich automatisch erstellt werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877e7e37",
   "metadata": {},
   "source": [
    "### Hole die benötigten Informationen für das PV\n",
    "\n",
    "Die Ceph-Monitor-Adressen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd0a7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "kubectl -n rook-ceph get cm rook-ceph-mon-endpoints -o jsonpath='{.data.data}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ada34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "kubectl apply -f - <<EOF\n",
    "apiVersion: v1\n",
    "kind: PersistentVolume\n",
    "metadata:\n",
    "  name: cephfs-pv\n",
    "spec:\n",
    "  capacity:\n",
    "    storage: 5Gi  # Größe des Volumes anpassen\n",
    "  accessModes:\n",
    "    - ReadWriteMany  # CephFS unterstützt RWX\n",
    "  persistentVolumeReclaimPolicy: Retain\n",
    "  storageClassName: rook-cephfs   # Muss mit deiner StorageClass übereinstimmen\n",
    "  csi:\n",
    "    driver: rook-ceph.cephfs.csi.ceph.com\n",
    "    volumeHandle: myfs  # Name des CephFS-Dateisystems\n",
    "    volumeAttributes:\n",
    "      clusterID: rook-ceph\n",
    "      fsName: myfs\n",
    "      pool: myfs-data0\n",
    "      provisionVolume: \"true\" \n",
    "      monitors: \"10.152.183.173:6789\"\n",
    "    nodeStageSecretRef:\n",
    "      name: rook-csi-cephfs-node\n",
    "      namespace: rook-ceph\n",
    "EOF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cf9255",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "kubectl apply -f - <<EOF\n",
    "apiVersion: v1\n",
    "kind: PersistentVolumeClaim\n",
    "metadata:\n",
    "  name: ceph-pvc\n",
    "\n",
    "spec:\n",
    "  accessModes:\n",
    "    - ReadWriteMany\n",
    "  resources:\n",
    "    requests:\n",
    "      storage: 5Gi\n",
    "  storageClassName: rook-cephfs\n",
    "  volumeName: cephfs-pv  # Name des vorher erstellten PVs\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d143d53a",
   "metadata": {},
   "source": [
    "Wir kontrollieren ob alles sauber erstellt wurde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5505871",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "kubectl describe pvc ceph-pvc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb502ea",
   "metadata": {},
   "source": [
    "Pod mit Ceph-Speicher starten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d077f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "kubectl apply -f - <<EOF\n",
    "apiVersion: v1\n",
    "kind: Pod\n",
    "metadata:\n",
    "  name: ceph-test-pod\n",
    "\n",
    "spec:\n",
    "  containers:\n",
    "  - name: busybox\n",
    "    image: busybox\n",
    "    command: [\"/bin/sh\", \"-c\", \"while true; do echo 'Ceph läuft!' >> /mnt/test/data.txt; sleep 10; done\"]\n",
    "    volumeMounts:\n",
    "    - mountPath: \"/mnt/test\"\n",
    "      name: ceph-storage\n",
    "  volumes:\n",
    "  - name: ceph-storage\n",
    "    persistentVolumeClaim:\n",
    "      claimName: ceph-pvc\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e764f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "kubectl describe pod ceph-test-pod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aa4719",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Aufräumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359e48de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "kubectl delete pod ceph-test-pod \n",
    "kubectl delete pvc ceph-pvc\n",
    "kubectl delete pv cephfs-pv \n",
    "kubectl delete sc rook-cephfs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc497463",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ecb844",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "kubectl -n rook-ceph exec deploy/rook-ceph-tools -- ceph status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b139eacc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
