{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d7e1c06-fd3a-46ee-926d-0d3dd73de6ea",
   "metadata": {},
   "source": [
    "Ãœbung: 3 VMs zu einem Kubernetes Cluster verbinden (k3s in kubevirt - Variante)\n",
    "--------------------------------------------------\n",
    "\n",
    "K3s bietet eine einfache und effiziente MÃ¶glichkeit, Kubernetes-Cluster lokal oder in Produktionsumgebungen zu betreiben. \n",
    "\n",
    "Das HinzufÃ¼gen von Nodes zu einem bestehenden K3s-Cluster erfolgt Ã¼ber den Befehl `curl -sfL https://get.k3s.io`. \n",
    "\n",
    "- - -\n",
    "\n",
    "Um die VorgÃ¤nge zu visualisieren starten wird Kubernetes Dashboard und scrollen rechts herunter zu Cluster -> Nodes\n",
    "\n",
    "WÃ¤hlt dazu nachfolgenden Link an und aktzeptiert das Zertifikat um dann ohne Token, drÃ¼ckt \"Ãœberspringen\" oder \"Skip\", ins Dashboard zu wechseln.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7600892f-24a8-4711-969b-867724f02d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "! echo \"https://\"$(cat ~/work/server-ip)\":30443\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d804e7c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "###  Worker Nodes zur Control Plane hinzufÃ¼gen (k3s + kubevirt Variante)\n",
    "\n",
    "* Dazu holen wir uns zuerst den Token von der Control Plane Node\n",
    "* Installieren k3s auf der Worker Node\n",
    "* Joinen die Worker Node mit der Control Plane Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92cdaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "SERVER_WG_IP=\"$(ip -4 addr show wg0 | awk '/inet /{print $2}' | cut -d/ -f1)\"\n",
    "SERVER_NAT_IP=\"$(hostname -I | awk '{print $1}')\"\n",
    "\n",
    "K3S_URL=\"https://${SERVER_WG_IP:-$SERVER_NAT_IP}:6443\"\n",
    "TOKEN=\"$(sudo cat /var/lib/rancher/k3s/server/node-token)\"\n",
    "\n",
    "join_node() {\n",
    "  NODE=\"$1\"\n",
    "\n",
    "  echo \"ðŸ”— [INFO] Verbinde $NODE\"\n",
    "\n",
    "  ssh \"$NODE\" bash -s <<EOF\n",
    "set -e\n",
    "\n",
    "echo \"ðŸ§  [INFO] PrÃ¼fe Netzwerk auf \\$(hostname)\"\n",
    "\n",
    "WG_IP=\\$(ip -4 addr show wg0 2>/dev/null | awk '/inet /{print \\$2}' | cut -d/ -f1)\n",
    "\n",
    "BASE_ARGS=\"agent --server $K3S_URL --token $TOKEN\"\n",
    "\n",
    "if [ -n \"\\$WG_IP\" ]; then\n",
    "  echo \"ðŸ” [INFO] WireGuard erkannt (\\$WG_IP)\"\n",
    "  K3S_ARGS=\"\\$BASE_ARGS --node-ip=\\$WG_IP --flannel-iface=wg0\"\n",
    "else\n",
    "  echo \"ðŸŒ [INFO] Kein WireGuard â€“ NAT Join\"\n",
    "  K3S_ARGS=\"\\$BASE_ARGS\"\n",
    "fi\n",
    "\n",
    "if systemctl is-active --quiet k3s-agent; then\n",
    "  echo \"âš ï¸ [WARN] k3s-agent lÃ¤uft bereits â€“ Ã¼berspringe\"\n",
    "  exit 0\n",
    "fi\n",
    "\n",
    "echo \"â–¶ï¸ [INFO] Starte Join: \\$K3S_ARGS\"\n",
    "\n",
    "curl -sfL https://get.k3s.io | INSTALL_K3S_EXEC=\"\\$K3S_ARGS\" sh -\n",
    "EOF\n",
    "}\n",
    "\n",
    "# === Nodes hier auflisten ===\n",
    "join_node duk-lernvirt-vm-1\n",
    "join_node duk-lernvirt-vm-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dc7f96-547b-49bc-adf1-1e44392f0d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! kubectl get nodes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b18fe55-97af-40d9-8724-c2702acbfd25",
   "metadata": {},
   "source": [
    "- - -\n",
    "\n",
    "### Zentraler Persistenter Speicher\n",
    "\n",
    "Damit alle Kubernetes Nodes (Master + Worker) den gleichen zentralen Persistenten Speicher verwenden, wurder vorher auf dem Master ein NFS Share /data eingerichtet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a2434b-e162-42e1-8832-e052ca7e4491",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat /etc/exports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bba661-6bf2-44f3-a148-b0260801186e",
   "metadata": {},
   "source": [
    "Damit mÃ¼ssen sich jetzt noch die Worker Nodes verbinden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecf5d8c-270c-47d4-af9e-71e73874f616",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "SERVER_WG_IP=\"$(ip -4 addr show wg0 | awk '/inet /{print $2}' | cut -d/ -f1)\"\n",
    "SERVER_NAT_IP=\"$(hostname -I | awk '{print $1}')\"\n",
    "\n",
    "SERVER_IP=\"${SERVER_WG_IP:-$SERVER_NAT_IP}\"\n",
    "ssh duk-lernvirt-vm-1 -- \"sudo umount /data ; sudo mount -t nfs $SERVER_IP:/data /data; df -h | grep /data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebbecc6-0f52-48bb-8cef-7f0df9078ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "SERVER_WG_IP=\"$(ip -4 addr show wg0 | awk '/inet /{print $2}' | cut -d/ -f1)\"\n",
    "SERVER_NAT_IP=\"$(hostname -I | awk '{print $1}')\"\n",
    "\n",
    "SERVER_IP=\"${SERVER_WG_IP:-$SERVER_NAT_IP}\"\n",
    "ssh duk-lernvirt-vm-2 -- \"sudo umount /data ; sudo mount -t nfs $SERVER_IP:/data /data; df -h | grep /data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0ab628",
   "metadata": {},
   "source": [
    "Die entsprechende Dateiablage, sogenannte PersistentVolumes (PV) in Kubernetes, wurde beim Installieren von Kubernetes eingerichtet. Das PersistentVolumes zeigt auf das Verzeichnis `/data`, siehe Eintrag `hostPath`.\n",
    "\n",
    "Diese Einrichtung ermÃ¶glicht die Trennung von Speicher und Container-Lebenszyklus, sodass Daten Ã¼ber Container-(Pod)-Neustarts und -LÃ¶schungen hinaus bestehen bleiben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fd2a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "kubectl get pv -o go-template='{{ range .items }}\n",
    "apiVersion: v1\n",
    "kind: PersistentVolume\n",
    "metadata:\n",
    "  name: {{ .metadata.name }}\n",
    "spec:\n",
    "  capacity:\n",
    "    storage: {{ .spec.capacity.storage }}\n",
    "  accessModes:\n",
    "  {{- range .spec.accessModes }}\n",
    "    - {{ . }}\n",
    "  {{- end }}\n",
    "  storageClassName: {{ .spec.storageClassName }}\n",
    "  persistentVolumeReclaimPolicy: {{ .spec.persistentVolumeReclaimPolicy }}\n",
    "  volumeMode: {{ .spec.volumeMode }}\n",
    "\n",
    "  {{- if .spec.hostPath }}\n",
    "  hostPath:\n",
    "    path: {{ .spec.hostPath.path }}\n",
    "    type: {{ .spec.hostPath.type }}\n",
    "  {{- end }}\n",
    "\n",
    "  {{- if .spec.claimRef }}\n",
    "  claimRef:\n",
    "    namespace: {{ .spec.claimRef.namespace }}\n",
    "    name: {{ .spec.claimRef.name }}\n",
    "  {{- end }}\n",
    "status:\n",
    "  phase: {{ .status.phase }}\n",
    "---\n",
    "{{ end }}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc81ee40",
   "metadata": {},
   "source": [
    "Im Kubernetes Dashboard finden wir den Eintrag in dem wir rechts herunterscrollen auf Cluster -> PersistentVolumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c030eb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "! echo \"https://\"$(cat ~/work/server-ip)\":30443\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d10d85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
